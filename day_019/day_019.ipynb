{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Day 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speech contains 66 lines and 2366 words\n"
     ]
    }
   ],
   "source": [
    "# Write a function which count number of lines and number of words in a text. All the files are in the data the folder: \n",
    "#a) Read obama_speech.txt file and count number of lines and words \n",
    "#b) Read michelle_obama_speech.txt file and count number of lines and words \n",
    "#c) Read donald_speech.txt file and count number of lines and words \n",
    "#d) Read melina_trump_speech.txt file and count number of lines and words\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "text_file_path = os.path.join(current_directory, \"obama_speech.txt\")\n",
    "if os.path.exists(text_file_path):\n",
    "        with open(text_file_path,\"r\") as f:\n",
    "                content = f.read()        \n",
    "else:\n",
    "        print(\"File can't be fount\")\n",
    "if os.path.exists(text_file_path):\n",
    "    with open(text_file_path, \"r\") as f:\n",
    "          lines = f.readlines()\n",
    "content = content.split(\" \")\n",
    "lines_number = len(lines)\n",
    "word_number = len(content)\n",
    "print(f\"The speech contains {lines_number} lines and {word_number} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def most_spoken_languages(filename, top_n):\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "               countries_data = json.load(file)\n",
    "\n",
    "        all_languages = [language for country_data in countries_data.values(\n",
    "        ) for language in country_data.get('languages', [])]\n",
    "\n",
    "\n",
    "        language_counter = Counter(all_languages)\n",
    "\n",
    "\n",
    "        top_languages = language_counter.most_common(top_n)\n",
    "\n",
    "        return top_languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries\n",
    "import json\n",
    "from collections import Counter\n",
    "def most_populated_countried(filename, num):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "                countries_data = json.load(f)\n",
    "        all_population = [countries_data.get('population', 0) for country_data in countries_data.value()]\n",
    "        sorted_population = sorted(all_population, reverse=True)\n",
    "        top_countries = []\n",
    "        for population in sorted_population[:num]:\n",
    "                for country, country_data in countries_data.items():\n",
    "                        if country_data.get('population', 0) == population and country not in top_countries:\n",
    "                                top_countries.append((population, country))\n",
    "                        break\n",
    "        return top_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries\n",
    "import json\n",
    "\n",
    "\n",
    "def most_populated_countries(filename, num):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "                countries_population = json.load(f)\n",
    "\n",
    "        top_countries = []\n",
    "        countries_data_list = [{'country': country, 'population': country_data.get('population', 0)} for country, country_data in countries_population.items()]\n",
    "\n",
    "        sorted_countries_data = sorted(countries_data_list, key=lambda x: x['population'], reverse=True)\n",
    "\n",
    "        top_countries = sorted_countries_data[:num]\n",
    "        return top_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all incoming email addresses as a list from the email_exchange_big.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order. Check the output\n",
    "from collections import Counter\n",
    "def find_most_common_words(data, num):\n",
    "        if isinstance(data, str):\n",
    "                words = data.split()\n",
    "        else:\n",
    "              words = data.read().split()\n",
    "        word_counts = Counter(words)\n",
    "        top_words = word_counts.most_common(num)\n",
    "        return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Obama's speech|:\n",
      "e appeared 1337 times\n",
      "t appeared 967 times\n",
      "o appeared 851 times\n",
      "a appeared 823 times\n",
      "n appeared 744 times\n",
      "r appeared 736 times\n",
      "s appeared 719 times\n",
      "i appeared 641 times\n",
      "h appeared 549 times\n",
      "d appeared 436 times\n"
     ]
    }
   ],
   "source": [
    "# Use the function, find_most_frequent_words to find: \n",
    "# a) The ten most frequent words used in Obama's speech \n",
    "# b) The ten most frequent words used in Michelle's speech \n",
    "# c) The ten most frequent words used in Trump's speech \n",
    "# d) The ten most frequent words used in Melina's speech\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def find_most_frequent_words(filename):\n",
    "        current_directory = os.getcwd()\n",
    "        text_file_path = os.path.join(current_directory, filename)\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "                read_content = file.read()\n",
    "        read_content.split()\n",
    "        count_word = Counter(read_content)\n",
    "        top_word = count_word.most_common()\n",
    "        top_word = top_word[1:11]\n",
    "        return top_word\n",
    "\n",
    "\n",
    "top_word = find_most_frequent_words('obama_speech.txt')\n",
    "print(f\"For Obama's speech:\")\n",
    "for i in top_word:\n",
    "        print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Donald's speech:\n",
      "e appeared 724 times\n",
      "o appeared 476 times\n",
      "t appeared 459 times\n",
      "a appeared 436 times\n",
      "i appeared 426 times\n",
      "r appeared 425 times\n",
      "n appeared 418 times\n",
      "s appeared 311 times\n",
      "l appeared 297 times\n",
      "h appeared 246 times\n"
     ]
    }
   ],
   "source": [
    "top_word = find_most_frequent_words('donald_trump_speech.txt')\n",
    "print(f\"For Trump's speech:\")\n",
    "for i in top_word:\n",
    "    print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Melina's speech:\n",
      "e appeared 696 times\n",
      "t appeared 492 times\n",
      "o appeared 470 times\n",
      "n appeared 468 times\n",
      "a appeared 463 times\n",
      "i appeared 373 times\n",
      "s appeared 365 times\n",
      "r appeared 357 times\n",
      "h appeared 292 times\n",
      "d appeared 249 times\n"
     ]
    }
   ],
   "source": [
    "top_word = find_most_frequent_words('melina_trump_speech.txt')\n",
    "print(f\"For Melina's speech:\")\n",
    "for i in top_word:\n",
    "    print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Michelle's speech:\n",
      "e appeared 1083 times\n",
      "t appeared 829 times\n",
      "o appeared 749 times\n",
      "a appeared 685 times\n",
      "h appeared 596 times\n",
      "n appeared 587 times\n",
      "i appeared 576 times\n",
      "r appeared 565 times\n",
      "s appeared 505 times\n",
      "d appeared 368 times\n"
     ]
    }
   ],
   "source": [
    "top_word = find_most_frequent_words('michelle_obama_speech.txt')\n",
    "print(f\"For Michelle's speech:\")\n",
    "for i in top_word:\n",
    "    print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python application that checks similarity between two texts. It takes a file or a string as a parameter and it will evaluate the similarity of the two texts. For instance check the similarity between the transcripts of Michelle's and Melina's speech. You may need a couple of functions, function to clean the text(clean_text), function to remove support words(remove_support_words) and finally to check the similarity(check_text_similarity). List of stop words are in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Number of lines containing 'python' or 'Python': 180\n",
      "b) Number of lines containing 'JavaScript', 'javascript', or 'Javascript': 184\n",
      "c) Number of lines containing 'Java' and not 'JavaScript': 67\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "text_file_path = os.path.join(current_directory, 'hacker_news.csv')\n",
    "\n",
    "python_sum = 0\n",
    "javascript_sum = 0\n",
    "java_sum = 0\n",
    "\n",
    "with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.readlines()\n",
    "\n",
    "for line in content:\n",
    "        lowercase_line = line.lower()\n",
    "\n",
    "\n",
    "        if 'python' in lowercase_line:\n",
    "                python_sum += 1\n",
    "\n",
    "\n",
    "        if 'javascript' in lowercase_line:\n",
    "                javascript_sum += 1\n",
    "\n",
    "\n",
    "        if 'java' in lowercase_line and 'javascript' not in lowercase_line:\n",
    "                java_sum += 1\n",
    "\n",
    "print(f\"a) Number of lines containing 'python' or 'Python': {python_sum}\")\n",
    "print(f\"b) Number of lines containing 'JavaScript', 'javascript', or 'Javascript': {javascript_sum}\")\n",
    "print(f\"c) Number of lines containing 'Java' and not 'JavaScript': {java_sum}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
