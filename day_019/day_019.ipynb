{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Day 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama's speech contains 66 lines and 2366 words\n",
      "Michelle's speech contains 83 lines and 2163 words\n",
      "Trump's speech contains 48 lines and 1214 words\n",
      "Mellina's speech contains 33 lines and 1359 words\n"
     ]
    }
   ],
   "source": [
    "# Write a function which count number of lines and number of words in a text. All the files are in the data the folder: \n",
    "#a) Read obama_speech.txt file and count number of lines and words \n",
    "#b) Read michelle_obama_speech.txt file and count number of lines and words \n",
    "#c) Read donald_speech.txt file and count number of lines and words \n",
    "#d) Read melina_trump_speech.txt file and count number of lines and words\n",
    "import os\n",
    "def count_lines_and_words(filename):\n",
    "        current_directory = os.getcwd()\n",
    "        text_file_path = os.path.join(current_directory, filename)\n",
    "        if os.path.exists(text_file_path):\n",
    "                with open(text_file_path,\"r\") as f:\n",
    "                        content = f.read()        \n",
    "        else:\n",
    "                print(\"File can't be fount\")\n",
    "        if os.path.exists(text_file_path):\n",
    "                with open(text_file_path, \"r\") as f:\n",
    "                        lines = f.readlines()\n",
    "        content = content.split(\" \")\n",
    "        lines_number = len(lines)\n",
    "        word_number = len(content)\n",
    "        return (f\"speech contains {lines_number} lines and {word_number} words\")\n",
    "# Obama's Speech\n",
    "word = count_lines_and_words(\"obama_speech.txt\")\n",
    "print(f\"Obama's {word}\")\n",
    "# Michelle's Speech\n",
    "word = count_lines_and_words(\"michelle_obama_speech.txt\")\n",
    "print(f\"Michelle's {word}\")\n",
    "# Donald Trump's Spheech\n",
    "word = count_lines_and_words(\"donald_trump_speech.txt\")\n",
    "print(f\"Trump's {word}\")\n",
    "# Melina's Speech\n",
    "word = count_lines_and_words(\"melina_trump_speech.txt\")\n",
    "print(f\"Mellina's {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('English', 91), ('French', 45), ('Arabic', 25), ('Spanish', 24), ('Portuguese', 9), ('Russian', 9), ('Dutch', 8), ('German', 7), ('Chinese', 5), ('Serbian', 4)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def most_spoken_languages(filename, top_n):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        countries_data = json.load(file)\n",
    "\n",
    "    all_languages = []\n",
    "\n",
    "    for country in countries_data:\n",
    "        languages = country['languages']\n",
    "\n",
    "        all_languages.extend(languages)\n",
    "\n",
    "    language_counter = Counter(all_languages)\n",
    "\n",
    "    top_languages = language_counter.most_common(top_n)\n",
    "\n",
    "    return top_languages\n",
    "\n",
    "\n",
    "print(most_spoken_languages(filename='./data/countries_data.json', top_n= 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'country': 'China', 'population': 1377422166}, {'country': 'India', 'population': 1295210000}, {'country': 'United States of America', 'population': 323947000}, {'country': 'Indonesia', 'population': 258705000}, {'country': 'Brazil', 'population': 206135893}, {'country': 'Pakistan', 'population': 194125062}, {'country': 'Nigeria', 'population': 186988000}, {'country': 'Bangladesh', 'population': 161006790}, {'country': 'Russian Federation', 'population': 146599183}, {'country': 'Japan', 'population': 126960000}]\n"
     ]
    }
   ],
   "source": [
    "# Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries\n",
    "import json\n",
    "def most_populated_countries(filename, num):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        countries_data = json.load(f)\n",
    "\n",
    "    countries_list = [{'country': country['name'],\n",
    "                       'population': country['population']} for country in countries_data]\n",
    "\n",
    "\n",
    "    sorted_countries = sorted(\n",
    "        countries_list, key=lambda x: x['population'], reverse=True)\n",
    "\n",
    "    top_countries = sorted_countries[:num]\n",
    "\n",
    "    return top_countries\n",
    "\n",
    "\n",
    "result_10 = most_populated_countries(\n",
    "    filename='./data/countries_data.json', num=10)\n",
    "print(result_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all incoming email addresses as a list from the email_exchange_big.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 107), ('of', 81), ('to', 66), ('our', 58), ('we', 50), ('a', 48), ('that', 47), ('is', 36), ('-', 23), ('in', 22)]\n"
     ]
    }
   ],
   "source": [
    "# Find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order. Check the output\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "def find_most_common_words(filename, num):\n",
    "        current_directory  = os.getcwd()\n",
    "        text_file_path = os.path.join(current_directory, filename)\n",
    "        if os.path.exists(text_file_path):\n",
    "                with open(text_file_path, 'r', encoding='utf=8') as f:\n",
    "                        words_content = f.read()\n",
    "                        words = words_content.split(' ')\n",
    "        else:\n",
    "                words_content = filename\n",
    "\n",
    "                words = words_content.split(' ')\n",
    "\n",
    "        content = Counter(words)\n",
    "\n",
    "        top_words = content.most_common(num+1)\n",
    "        top_words = top_words[1:num+1]\n",
    "\n",
    "        return top_words\n",
    "print(find_most_common_words('obama_speech.txt', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Obama's speech:\n",
      "e appeared 1337 times\n",
      "t appeared 967 times\n",
      "o appeared 851 times\n",
      "a appeared 823 times\n",
      "n appeared 744 times\n",
      "r appeared 736 times\n",
      "s appeared 719 times\n",
      "i appeared 641 times\n",
      "h appeared 549 times\n",
      "d appeared 436 times\n"
     ]
    }
   ],
   "source": [
    "# Use the function, find_most_frequent_words to find: \n",
    "# a) The ten most frequent words used in Obama's speech \n",
    "# b) The ten most frequent words used in Michelle's speech \n",
    "# c) The ten most frequent words used in Trump's speech \n",
    "# d) The ten most frequent words used in Melina's speech\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def find_most_frequent_words(filename):\n",
    "        current_directory = os.getcwd()\n",
    "        text_file_path = os.path.join(current_directory, filename)\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "                read_content = file.read()\n",
    "        read_content.split()\n",
    "        count_word = Counter(read_content)\n",
    "        top_word = count_word.most_common()\n",
    "        top_word = top_word[1:11]\n",
    "        return top_word\n",
    "\n",
    "\n",
    "top_word = find_most_frequent_words('obama_speech.txt')\n",
    "print(f\"For Obama's speech:\")\n",
    "for i in top_word:\n",
    "        print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Trump's speech:\n",
      "e appeared 724 times\n",
      "o appeared 476 times\n",
      "t appeared 459 times\n",
      "a appeared 436 times\n",
      "i appeared 426 times\n",
      "r appeared 425 times\n",
      "n appeared 418 times\n",
      "s appeared 311 times\n",
      "l appeared 297 times\n",
      "h appeared 246 times\n"
     ]
    }
   ],
   "source": [
    "top_word = find_most_frequent_words('donald_trump_speech.txt')\n",
    "print(f\"For Trump's speech:\")\n",
    "for i in top_word:\n",
    "    print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Melina's speech:\n",
      "e appeared 696 times\n",
      "t appeared 492 times\n",
      "o appeared 470 times\n",
      "n appeared 468 times\n",
      "a appeared 463 times\n",
      "i appeared 373 times\n",
      "s appeared 365 times\n",
      "r appeared 357 times\n",
      "h appeared 292 times\n",
      "d appeared 249 times\n"
     ]
    }
   ],
   "source": [
    "top_word = find_most_frequent_words('melina_trump_speech.txt')\n",
    "print(f\"For Melina's speech:\")\n",
    "for i in top_word:\n",
    "    print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Michelle's speech:\n",
      "e appeared 1083 times\n",
      "t appeared 829 times\n",
      "o appeared 749 times\n",
      "a appeared 685 times\n",
      "h appeared 596 times\n",
      "n appeared 587 times\n",
      "i appeared 576 times\n",
      "r appeared 565 times\n",
      "s appeared 505 times\n",
      "d appeared 368 times\n"
     ]
    }
   ],
   "source": [
    "top_word = find_most_frequent_words('michelle_obama_speech.txt')\n",
    "print(f\"For Michelle's speech:\")\n",
    "for i in top_word:\n",
    "    print(f\"{i[0]} appeared {i[1]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python application that checks similarity between two texts. It takes a file or a string as a parameter and it will evaluate the similarity of the two texts. For instance check the similarity between the transcripts of Michelle's and Melina's speech. You may need a couple of functions, function to clean the text(clean_text), function to remove support words(remove_support_words) and finally to check the similarity(check_text_similarity). List of stop words are in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Number of lines containing 'python' or 'Python': 180\n",
      "b) Number of lines containing 'JavaScript', 'javascript', or 'Javascript': 184\n",
      "c) Number of lines containing 'Java' and not 'JavaScript': 67\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "text_file_path = os.path.join(current_directory, 'hacker_news.csv')\n",
    "\n",
    "python_sum = 0\n",
    "javascript_sum = 0\n",
    "java_sum = 0\n",
    "\n",
    "with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.readlines()\n",
    "\n",
    "for line in content:\n",
    "        lowercase_line = line.lower()\n",
    "\n",
    "\n",
    "        if 'python' in lowercase_line:\n",
    "                python_sum += 1\n",
    "\n",
    "\n",
    "        if 'javascript' in lowercase_line:\n",
    "                javascript_sum += 1\n",
    "\n",
    "\n",
    "        if 'java' in lowercase_line and 'javascript' not in lowercase_line:\n",
    "                java_sum += 1\n",
    "\n",
    "print(f\"a) Number of lines containing 'python' or 'Python': {python_sum}\")\n",
    "print(f\"b) Number of lines containing 'JavaScript', 'javascript', or 'Javascript': {javascript_sum}\")\n",
    "print(f\"c) Number of lines containing 'Java' and not 'JavaScript': {java_sum}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
